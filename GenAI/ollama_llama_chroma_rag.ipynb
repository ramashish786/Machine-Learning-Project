{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k8KZ-mb2ui7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from flask import Flask, request\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "folder_path = \"db\"\n",
        "\n",
        "cached_llm = Ollama(model=\"llama3\")\n",
        "\n",
        "embedding = FastEmbedEmbeddings()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024, chunk_overlap=80, length_function=len, is_separator_regex=False\n",
        ")\n",
        "\n",
        "raw_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    <s>[INST] You are a technical assistant good at searching docuemnts. If you do not have an answer from the provided information say so. [/INST] </s>\n",
        "    [INST] {input}\n",
        "           Context: {context}\n",
        "           Answer:\n",
        "    [/INST]\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "@app.route(\"/ai\", methods=[\"POST\"])\n",
        "def aiPost():\n",
        "    print(\"Post /ai called\")\n",
        "    json_content = request.json\n",
        "    query = json_content.get(\"query\")\n",
        "\n",
        "    print(f\"query: {query}\")\n",
        "\n",
        "    response = cached_llm.invoke(query)\n",
        "\n",
        "    print(response)\n",
        "\n",
        "    response_answer = {\"answer\": response}\n",
        "    return response_answer\n",
        "\n",
        "\n",
        "@app.route(\"/ask_pdf\", methods=[\"POST\"])\n",
        "def askPDFPost():\n",
        "    print(\"Post /ask_pdf called\")\n",
        "    json_content = request.json\n",
        "    query = json_content.get(\"query\")\n",
        "\n",
        "    print(f\"query: {query}\")\n",
        "\n",
        "    print(\"Loading vector store\")\n",
        "    vector_store = Chroma(persist_directory=folder_path, embedding_function=embedding)\n",
        "\n",
        "    print(\"Creating chain\")\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"similarity_score_threshold\",\n",
        "        search_kwargs={\n",
        "            \"k\": 20,\n",
        "            \"score_threshold\": 0.1,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    document_chain = create_stuff_documents_chain(cached_llm, raw_prompt)\n",
        "    chain = create_retrieval_chain(retriever, document_chain)\n",
        "\n",
        "    result = chain.invoke({\"input\": query})\n",
        "\n",
        "    print(result)\n",
        "\n",
        "    sources = []\n",
        "    for doc in result[\"context\"]:\n",
        "        sources.append(\n",
        "            {\"source\": doc.metadata[\"source\"], \"page_content\": doc.page_content}\n",
        "        )\n",
        "\n",
        "    response_answer = {\"answer\": result[\"answer\"], \"sources\": sources}\n",
        "    return response_answer\n",
        "\n",
        "\n",
        "@app.route(\"/pdf\", methods=[\"POST\"])\n",
        "def pdfPost():\n",
        "    file = request.files[\"file\"]\n",
        "    file_name = file.filename\n",
        "    save_file = \"pdf/\" + file_name\n",
        "    file.save(save_file)\n",
        "    print(f\"filename: {file_name}\")\n",
        "\n",
        "    loader = PDFPlumberLoader(save_file)\n",
        "    docs = loader.load_and_split()\n",
        "    print(f\"docs len={len(docs)}\")\n",
        "\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "    print(f\"chunks len={len(chunks)}\")\n",
        "\n",
        "    vector_store = Chroma.from_documents(\n",
        "        documents=chunks, embedding=embedding, persist_directory=folder_path\n",
        "    )\n",
        "\n",
        "    vector_store.persist()\n",
        "\n",
        "    response = {\n",
        "        \"status\": \"Successfully Uploaded\",\n",
        "        \"filename\": file_name,\n",
        "        \"doc_len\": len(docs),\n",
        "        \"chunks\": len(chunks),\n",
        "    }\n",
        "    return response\n",
        "\n",
        "\n",
        "def start_app():\n",
        "    app.run(host=\"0.0.0.0\", port=8080, debug=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_app()"
      ]
    }
  ]
}